{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poker Rule Induction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0: Nothing in hand; not a recognized poker hand \n",
    "1: One pair; one pair of equal ranks within five cards\n",
    "2: Two pairs; two pairs of equal ranks within five cards\n",
    "3: Three of a kind; three equal ranks within five cards\n",
    "4: Straight; five cards, sequentially ranked with no gaps\n",
    "5: Flush; five cards with the same suit\n",
    "6: Full house; pair + different rank three of a kind\n",
    "7: Four of a kind; four equal ranks within five cards\n",
    "8: Straight flush; straight + flush\n",
    "9: Royal flush; {Ace, King, Queen, Jack, Ten} + flush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels  as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('poker-hand-training-true.data.txt',\n",
    "                  names=['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5','Type'])\n",
    "test=pd.read_csv('poker-hand-testing.data.txt',\n",
    "                 names=['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5','Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>C1</th>\n",
       "      <th>S2</th>\n",
       "      <th>C2</th>\n",
       "      <th>S3</th>\n",
       "      <th>C3</th>\n",
       "      <th>S4</th>\n",
       "      <th>C4</th>\n",
       "      <th>S5</th>\n",
       "      <th>C5</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S1  C1  S2  C2  S3  C3  S4  C4  S5  C5  Type\n",
       "0   1  10   1  11   1  13   1  12   1   1     9\n",
       "1   2  11   2  13   2  10   2  12   2   1     9\n",
       "2   3  12   3  11   3  13   3  10   3   1     9\n",
       "3   4  10   4  11   4   1   4  13   4  12     9\n",
       "4   4   1   4  13   4  12   4  11   4  10     9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Basic statistics about each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>C1</th>\n",
       "      <th>S2</th>\n",
       "      <th>C2</th>\n",
       "      <th>S3</th>\n",
       "      <th>C3</th>\n",
       "      <th>S4</th>\n",
       "      <th>C4</th>\n",
       "      <th>S5</th>\n",
       "      <th>C5</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25010.000000</td>\n",
       "      <td>25010.000000</td>\n",
       "      <td>25010.000000</td>\n",
       "      <td>25010.000000</td>\n",
       "      <td>25010.000000</td>\n",
       "      <td>25010.000000</td>\n",
       "      <td>25010.000000</td>\n",
       "      <td>25010.000000</td>\n",
       "      <td>25010.000000</td>\n",
       "      <td>25010.000000</td>\n",
       "      <td>25010.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.508756</td>\n",
       "      <td>6.995242</td>\n",
       "      <td>2.497721</td>\n",
       "      <td>7.014194</td>\n",
       "      <td>2.510236</td>\n",
       "      <td>7.014154</td>\n",
       "      <td>2.495922</td>\n",
       "      <td>6.942463</td>\n",
       "      <td>2.497321</td>\n",
       "      <td>6.962735</td>\n",
       "      <td>0.621152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.116483</td>\n",
       "      <td>3.749805</td>\n",
       "      <td>1.121767</td>\n",
       "      <td>3.766974</td>\n",
       "      <td>1.123148</td>\n",
       "      <td>3.744974</td>\n",
       "      <td>1.116009</td>\n",
       "      <td>3.747147</td>\n",
       "      <td>1.118732</td>\n",
       "      <td>3.741579</td>\n",
       "      <td>0.788361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 S1            C1            S2            C2            S3  \\\n",
       "count  25010.000000  25010.000000  25010.000000  25010.000000  25010.000000   \n",
       "mean       2.508756      6.995242      2.497721      7.014194      2.510236   \n",
       "std        1.116483      3.749805      1.121767      3.766974      1.123148   \n",
       "min        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "25%        2.000000      4.000000      1.000000      4.000000      2.000000   \n",
       "50%        3.000000      7.000000      2.000000      7.000000      3.000000   \n",
       "75%        4.000000     10.000000      4.000000     10.000000      4.000000   \n",
       "max        4.000000     13.000000      4.000000     13.000000      4.000000   \n",
       "\n",
       "                 C3            S4            C4            S5            C5  \\\n",
       "count  25010.000000  25010.000000  25010.000000  25010.000000  25010.000000   \n",
       "mean       7.014154      2.495922      6.942463      2.497321      6.962735   \n",
       "std        3.744974      1.116009      3.747147      1.118732      3.741579   \n",
       "min        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "25%        4.000000      1.000000      4.000000      1.000000      4.000000   \n",
       "50%        7.000000      2.000000      7.000000      3.000000      7.000000   \n",
       "75%       10.000000      3.000000     10.000000      3.000000     10.000000   \n",
       "max       13.000000      4.000000     13.000000      4.000000     13.000000   \n",
       "\n",
       "               Type  \n",
       "count  25010.000000  \n",
       "mean       0.621152  \n",
       "std        0.788361  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        1.000000  \n",
       "75%        1.000000  \n",
       "max        9.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    6312\n",
      "2    6298\n",
      "3    6250\n",
      "1    6150\n",
      "Name: S1, dtype: int64\n",
      "1     1982\n",
      "9     1967\n",
      "7     1961\n",
      "8     1948\n",
      "2     1941\n",
      "12    1940\n",
      "11    1926\n",
      "4     1919\n",
      "13    1915\n",
      "5     1892\n",
      "3     1882\n",
      "10    1877\n",
      "6     1860\n",
      "Name: C1, dtype: int64\n",
      "1    6309\n",
      "4    6300\n",
      "2    6244\n",
      "3    6157\n",
      "Name: S2, dtype: int64\n",
      "13    2007\n",
      "1     1985\n",
      "6     1956\n",
      "12    1939\n",
      "11    1931\n",
      "10    1922\n",
      "2     1921\n",
      "7     1912\n",
      "3     1912\n",
      "4     1905\n",
      "8     1898\n",
      "9     1877\n",
      "5     1845\n",
      "Name: C2, dtype: int64\n",
      "4    6419\n",
      "1    6230\n",
      "2    6208\n",
      "3    6153\n",
      "Name: S3, dtype: int64\n",
      "10    2000\n",
      "12    1987\n",
      "3     1965\n",
      "4     1935\n",
      "7     1927\n",
      "5     1920\n",
      "11    1913\n",
      "8     1912\n",
      "13    1910\n",
      "2     1910\n",
      "1     1895\n",
      "6     1884\n",
      "9     1852\n",
      "Name: C3, dtype: int64\n",
      "3    6314\n",
      "1    6269\n",
      "2    6248\n",
      "4    6179\n",
      "Name: S4, dtype: int64\n",
      "3     1999\n",
      "2     1987\n",
      "1     1983\n",
      "11    1953\n",
      "9     1946\n",
      "7     1943\n",
      "10    1924\n",
      "6     1913\n",
      "4     1902\n",
      "5     1883\n",
      "13    1874\n",
      "8     1865\n",
      "12    1838\n",
      "Name: C4, dtype: int64\n",
      "3    6314\n",
      "1    6308\n",
      "4    6216\n",
      "2    6172\n",
      "Name: S5, dtype: int64\n",
      "8     1994\n",
      "1     1970\n",
      "5     1963\n",
      "2     1957\n",
      "10    1948\n",
      "4     1946\n",
      "9     1931\n",
      "3     1914\n",
      "11    1905\n",
      "6     1894\n",
      "13    1892\n",
      "12    1863\n",
      "7     1833\n",
      "Name: C5, dtype: int64\n",
      "0    12493\n",
      "1    10599\n",
      "2     1206\n",
      "3      513\n",
      "4       93\n",
      "5       54\n",
      "6       36\n",
      "7        6\n",
      "9        5\n",
      "8        5\n",
      "Name: Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for column in train.columns:\n",
    "    print(train[column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Draw histogram of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10ebd6e80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGA6SpI7hIEnqGA6SpI7hIEnq/D9Z/hMSawPDJAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bff0ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "train.Type.hist(rwidth=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25010, 11)\n",
      "(1000000, 11)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split both train and test into x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train=train[['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5']] \n",
    "y_train=train['Type']\n",
    "x_test=test[['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5']]\n",
    "y_test=test['Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Build a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tiger/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.68      0.62    501209\n",
      "          1       0.48      0.44      0.46    422498\n",
      "          2       0.17      0.02      0.04     47622\n",
      "          3       0.17      0.01      0.03     21121\n",
      "          4       0.08      0.00      0.01      3885\n",
      "          5       0.43      0.01      0.03      1996\n",
      "          6       0.05      0.00      0.00      1424\n",
      "          7       0.00      0.00      0.00       230\n",
      "          8       0.00      0.00      0.00        12\n",
      "          9       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.50      0.53      0.51   1000000\n",
      "\n",
      "0.531433\n",
      "------\n",
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tiger/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.74      0.65    501209\n",
      "          1       0.51      0.44      0.47    422498\n",
      "          2       0.21      0.01      0.03     47622\n",
      "          3       0.27      0.01      0.02     21121\n",
      "          4       0.10      0.00      0.00      3885\n",
      "          5       0.53      0.01      0.02      1996\n",
      "          6       0.06      0.00      0.00      1424\n",
      "          7       0.00      0.00      0.00       230\n",
      "          8       0.00      0.00      0.00        12\n",
      "          9       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.53      0.56      0.53   1000000\n",
      "\n",
      "0.558299\n",
      "------\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tiger/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.76      0.67    501209\n",
      "          1       0.53      0.46      0.49    422498\n",
      "          2       0.28      0.01      0.01     47622\n",
      "          3       0.32      0.00      0.01     21121\n",
      "          4       0.21      0.00      0.00      3885\n",
      "          5       0.87      0.01      0.01      1996\n",
      "          6       0.33      0.00      0.00      1424\n",
      "          7       0.00      0.00      0.00       230\n",
      "          8       0.00      0.00      0.00        12\n",
      "          9       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.55      0.57      0.54   1000000\n",
      "\n",
      "0.574388\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for n in [5,10,20]:\n",
    "    clf=RandomForestClassifier(n_estimators=n)\n",
    "    clf=clf.fit(x_train,y_train)\n",
    "    print(n)\n",
    "    print(classification_report(y_test,clf.predict(x_test)))\n",
    "    print(accuracy_score(y_test,clf.predict(x_test)))\n",
    "    print(\"------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[379949 121148     97      9      5      1      0      0      0      0]\n",
      " [227776 193964    629    114     13      1      1      0      0      0]\n",
      " [ 17179  30021    361     57      3      0      1      0      0      0]\n",
      " [  5203  15680    142     94      2      0      0      0      0      0]\n",
      " [   851   3010     15      3      6      0      0      0      0      0]\n",
      " [  1633    350      0      0      0     13      0      0      0      0]\n",
      " [   184   1202     25     12      0      0      1      0      0      0]\n",
      " [    16    202      4      8      0      0      0      0      0      0]\n",
      " [     3      9      0      0      0      0      0      0      0      0]\n",
      " [     1      2      0      0      0      0      0      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test,clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>C1</th>\n",
       "      <th>S2</th>\n",
       "      <th>C2</th>\n",
       "      <th>S3</th>\n",
       "      <th>C3</th>\n",
       "      <th>S4</th>\n",
       "      <th>C4</th>\n",
       "      <th>S5</th>\n",
       "      <th>C5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    S1  C1  S2  C2  S3  C3  S4  C4  S5  C5\n",
       "14   3   8   4  12   3   9   4   2   3   2\n",
       "19   3   7   2   7   4  11   1  12   3   1\n",
       "20   1  13   4   8   2   7   2  10   3  13"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[y_train==1].iloc[1:4,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add hand count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def concat_card_count(data_set):\n",
    "    suit_counts = []\n",
    "    for i in range(1,14):\n",
    "        each_counts = pd.concat([data_set.C1 ==i, data_set.C2 == i, data_set.C3 ==i, data_set.C4 == i, data_set.C5 ==i],axis=1)\n",
    "        suit_counts.append(np.sum(each_counts,axis=1))\n",
    "    suit_counts=np.vstack(suit_counts)\n",
    "    suit_counts_df=pd.DataFrame(suit_counts.transpose(),columns=['C{}_Count'.format(i) for i in range(1,14)])\n",
    "    return pd.concat([suit_counts_df,data_set], axis=1)\n",
    "\n",
    "x_train = concat_card_count(x_train)\n",
    "x_test=concat_card_count(x_test)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   C1_Count  C2_Count  C3_Count  C4_Count  C5_Count  C6_Count  C7_Count  \\\n",
      "1         1         0         0         0         0         0         0   \n",
      "2         1         0         0         0         0         0         0   \n",
      "\n",
      "   C8_Count  C9_Count  C10_Count  C11_Count  C12_Count  C13_Count  S1  \n",
      "1         0         0          1          1          1          1   2  \n",
      "2         0         0          1          1          1          1   3  \n",
      "   C1  S2  C2  S3  C3  S4  C4  S5  C5\n",
      "1  11   2  13   2  10   2  12   2   1\n",
      "2  12   3  11   3  13   3  10   3   1\n"
     ]
    }
   ],
   "source": [
    "print(x_train.iloc[1:3,0:14])\n",
    "print(x_train.iloc[1:3,14:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99    501209\n",
      "          1       1.00      1.00      1.00    422498\n",
      "          2       0.97      0.97      0.97     47622\n",
      "          3       0.98      0.99      0.99     21121\n",
      "          4       1.00      0.18      0.30      3885\n",
      "          5       0.00      0.00      0.00      1996\n",
      "          6       0.86      0.02      0.04      1424\n",
      "          7       0.00      0.00      0.00       230\n",
      "          8       0.00      0.00      0.00        12\n",
      "          9       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.99      0.99      0.99   1000000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tiger/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "clf=RandomForestClassifier(n_estimators=20)\n",
    "clf=clf.fit(x_train,y_train)\n",
    "print(classification_report(y_test,clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* F1 score for type 1 increased to 1, type 2 and type 3 improved a lot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Standard Deviation to help correctly classify Type 4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    501209\n",
      "          1       1.00      1.00      1.00    422498\n",
      "          2       0.97      0.98      0.98     47622\n",
      "          3       0.98      0.98      0.98     21121\n",
      "          4       1.00      0.90      0.95      3885\n",
      "          5       0.17      0.00      0.00      1996\n",
      "          6       0.94      0.04      0.07      1424\n",
      "          7       0.29      0.01      0.02       230\n",
      "          8       0.00      0.00      0.00        12\n",
      "          9       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.99      0.99      0.99   1000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train=train[['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5']] \n",
    "y_train=train['Type']\n",
    "x_test=test[['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5']]\n",
    "y_test=test['Type']\n",
    "\n",
    "def concat_card_count(data_set):\n",
    "    suit_counts = []\n",
    "    for i in range(1, 14):\n",
    "        each_counts = pd.concat([data_set.C1 == i, data_set.C2 == i, data_set.C3 == i, data_set.C4 == i,data_set.C5 == i], axis=1)\n",
    "        suit_counts.append(np.sum(each_counts, axis=1))\n",
    "    suit_counts = np.vstack(suit_counts)\n",
    "    suit_counts_df = pd.DataFrame(suit_counts.transpose(), columns=['C{}_Count'.format(i) for i in range(1,14)])\n",
    "    return pd.concat([suit_counts_df, data_set], axis=1)\n",
    "\n",
    "x_train = concat_card_count(x_train)\n",
    "x_test = concat_card_count(x_test)\n",
    "\n",
    "def concat_card_std(data_set):\n",
    "    std=np.std(data_set[['C1','C2','C3','C4','C5']],axis=1)\n",
    "    std_df=pd.DataFrame(std,columns=['Card_std'])\n",
    "    return pd.concat([std_df,data_set],axis=1)\n",
    "x_train=concat_card_std(x_train)\n",
    "x_test=concat_card_std(x_test)\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=20)\n",
    "clf=clf.fit(x_train,y_train)\n",
    "print(classification_report(y_test,clf.predict(x_test)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Card_std</th>\n",
       "      <th>C1_Count</th>\n",
       "      <th>C2_Count</th>\n",
       "      <th>C3_Count</th>\n",
       "      <th>C4_Count</th>\n",
       "      <th>C5_Count</th>\n",
       "      <th>C6_Count</th>\n",
       "      <th>C7_Count</th>\n",
       "      <th>C8_Count</th>\n",
       "      <th>C9_Count</th>\n",
       "      <th>...</th>\n",
       "      <th>S1</th>\n",
       "      <th>C1</th>\n",
       "      <th>S2</th>\n",
       "      <th>C2</th>\n",
       "      <th>S3</th>\n",
       "      <th>C3</th>\n",
       "      <th>S4</th>\n",
       "      <th>C4</th>\n",
       "      <th>S5</th>\n",
       "      <th>C5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>1.414214</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>1.414214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Card_std  C1_Count  C2_Count  C3_Count  C4_Count  C5_Count  C6_Count  \\\n",
       "643  1.414214         0         1         1         1         1         1   \n",
       "918  1.414214         0         0         0         0         1         1   \n",
       "\n",
       "     C7_Count  C8_Count  C9_Count ...  S1  C1  S2  C2  S3  C3  S4  C4  S5  C5  \n",
       "643         0         0         0 ...   3   3   3   6   4   4   1   2   2   5  \n",
       "918         1         1         1 ...   3   8   2   7   3   9   2   6   1   5  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[(y_test==4)&(clf.predict(x_test)!=4)][1:3]\n",
    "x_test[(y_test==4)&(clf.predict(x_test)==4)][1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance for type 4 increased a lot\n",
    "BUG: In one specific situation, 1 can be combined with 10,11,12,13 and becomes a type 4 \n",
    "FIX: Calculate std with 1, then replace all 1 with 14, calculate again, if the std is smaller, then replace old one with this one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fix type 4 error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    501209\n",
      "          1       0.99      1.00      1.00    422498\n",
      "          2       0.97      0.96      0.97     47622\n",
      "          3       0.98      0.97      0.97     21121\n",
      "          4       1.00      0.98      0.99      3885\n",
      "          5       0.09      0.00      0.00      1996\n",
      "          6       0.98      0.04      0.07      1424\n",
      "          7       0.25      0.00      0.01       230\n",
      "          8       0.00      0.00      0.00        12\n",
      "          9       0.02      0.33      0.04         3\n",
      "\n",
      "avg / total       0.99      0.99      0.99   1000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train=train[['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5']] \n",
    "y_train=train['Type']\n",
    "x_test=test[['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5']]\n",
    "y_test=test['Type']\n",
    "\n",
    "def concat_card_count(data_set):\n",
    "    suit_counts = []\n",
    "    for i in range(1, 14):\n",
    "        each_counts = pd.concat([data_set.C1 == i, data_set.C2 == i, data_set.C3 == i, data_set.C4 == i,data_set.C5 == i], axis=1)\n",
    "        suit_counts.append(np.sum(each_counts, axis=1))\n",
    "    suit_counts = np.vstack(suit_counts)\n",
    "    suit_counts_df = pd.DataFrame(suit_counts.transpose(), columns=['C{}_Count'.format(i) for i in range(1,14)])\n",
    "    return pd.concat([suit_counts_df, data_set], axis=1)\n",
    "\n",
    "x_train = concat_card_count(x_train)\n",
    "x_test = concat_card_count(x_test)\n",
    "\n",
    "def concat_card_std(data_set):\n",
    "    hands=data_set[['C1','C2','C3','C4','C5']].as_matrix()\n",
    "    std=np.std(hands,axis=1)\n",
    "    hands[hands==1] =14\n",
    "    new_std = np.std(hands, axis=1)\n",
    "    std[new_std<std] = new_std[new_std < std]\n",
    "    std_df=pd.DataFrame(std,columns=['Card_std'])\n",
    "    return pd.concat([std_df,data_set],axis=1)\n",
    "x_train=concat_card_std(x_train)\n",
    "x_test=concat_card_std(x_test)\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=20)\n",
    "clf=clf.fit(x_train,y_train)\n",
    "print(classification_report(y_test,clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type 4 bug is fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type 5 is related to same suits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add suit count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    501209\n",
      "          1       0.99      1.00      1.00    422498\n",
      "          2       0.98      0.96      0.97     47622\n",
      "          3       0.98      0.96      0.97     21121\n",
      "          4       1.00      1.00      1.00      3885\n",
      "          5       1.00      0.12      0.21      1996\n",
      "          6       0.91      0.03      0.06      1424\n",
      "          7       0.00      0.00      0.00       230\n",
      "          8       0.00      0.00      0.00        12\n",
      "          9       0.18      0.67      0.29         3\n",
      "\n",
      "avg / total       0.99      0.99      0.99   1000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train=train[['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5']] \n",
    "y_train=train['Type']\n",
    "x_test=test[['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5']]\n",
    "y_test=test['Type']\n",
    "\n",
    "def concat_card_count(data_set):\n",
    "    suit_counts = []\n",
    "    for i in range(1, 14):\n",
    "        each_counts = pd.concat([data_set.C1 == i, data_set.C2 == i, data_set.C3 == i, data_set.C4 == i,data_set.C5 == i], axis=1)\n",
    "        suit_counts.append(np.sum(each_counts, axis=1))\n",
    "    suit_counts = np.vstack(suit_counts)\n",
    "    suit_counts_df = pd.DataFrame(suit_counts.transpose(), columns=['C{}_Count'.format(i) for i in range(1,14)])\n",
    "    return pd.concat([suit_counts_df, data_set], axis=1)\n",
    "\n",
    "x_train = concat_card_count(x_train)\n",
    "x_test = concat_card_count(x_test)\n",
    "\n",
    "def concat_card_std(data_set):\n",
    "    hands=data_set[['C1','C2','C3','C4','C5']].as_matrix()\n",
    "    std=np.std(hands,axis=1)\n",
    "    hands[hands==1] =14\n",
    "    new_std = np.std(hands, axis=1)\n",
    "    std[new_std<std] = new_std[new_std < std]\n",
    "    std_df=pd.DataFrame(std,columns=['Card_std'])\n",
    "    return pd.concat([std_df,data_set],axis=1)\n",
    "x_train=concat_card_std(x_train)\n",
    "x_test=concat_card_std(x_test)\n",
    "\n",
    "def concat_suit_count(data_set):\n",
    "    suit_counts = []\n",
    "    for i in range(1, 5):\n",
    "        each_counts = pd.concat([data_set.S1 == i, data_set.S2 == i, data_set.S3 == i, data_set.S4 == i,data_set.S5 == i], axis=1)\n",
    "        suit_counts.append(np.sum(each_counts, axis=1))\n",
    "    suit_counts = np.vstack(suit_counts)\n",
    "    suit_counts_df = pd.DataFrame(suit_counts.transpose(), columns=['S{}_Count'.format(i) for i in range(1,5)])\n",
    "    return pd.concat([suit_counts_df, data_set], axis=1)\n",
    "\n",
    "x_train=concat_suit_count(x_train)\n",
    "x_test=concat_suit_count(x_test)\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=20)\n",
    "clf=clf.fit(x_train,y_train)\n",
    "print(classification_report(y_test,clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Adding suit count is improving the result but not perfect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add suit value count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    501209\n",
      "          1       0.99      1.00      0.99    422498\n",
      "          2       0.98      0.89      0.93     47622\n",
      "          3       0.97      0.95      0.96     21121\n",
      "          4       1.00      0.99      1.00      3885\n",
      "          5       1.00      1.00      1.00      1996\n",
      "          6       0.95      0.03      0.05      1424\n",
      "          7       0.00      0.00      0.00       230\n",
      "          8       1.00      0.58      0.74        12\n",
      "          9       0.60      1.00      0.75         3\n",
      "\n",
      "avg / total       0.99      0.99      0.99   1000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train=train[['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5']] \n",
    "y_train=train['Type']\n",
    "x_test=test[['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5']]\n",
    "y_test=test['Type']\n",
    "\n",
    "def concat_card_count(data_set):\n",
    "    suit_counts = []\n",
    "    for i in range(1, 14):\n",
    "        each_counts = pd.concat([data_set.C1 == i, data_set.C2 == i, data_set.C3 == i, data_set.C4 == i,data_set.C5 == i], axis=1)\n",
    "        suit_counts.append(np.sum(each_counts, axis=1))\n",
    "    suit_counts = np.vstack(suit_counts)\n",
    "    suit_counts_df = pd.DataFrame(suit_counts.transpose(), columns=['C{}_Count'.format(i) for i in range(1,14)])\n",
    "    return pd.concat([suit_counts_df, data_set], axis=1)\n",
    "\n",
    "x_train = concat_card_count(x_train)\n",
    "x_test = concat_card_count(x_test)\n",
    "\n",
    "def concat_card_std(data_set):\n",
    "    hands=data_set[['C1','C2','C3','C4','C5']].as_matrix()\n",
    "    std=np.std(hands,axis=1)\n",
    "    hands[hands==1] =14\n",
    "    new_std = np.std(hands, axis=1)\n",
    "    std[new_std<std] = new_std[new_std < std]\n",
    "    std_df=pd.DataFrame(std,columns=['Card_std'])\n",
    "    return pd.concat([std_df,data_set],axis=1)\n",
    "x_train=concat_card_std(x_train)\n",
    "x_test=concat_card_std(x_test)\n",
    "\n",
    "def concat_suit_count(data_set):\n",
    "    suit_counts = []\n",
    "    for i in range(1, 5):\n",
    "        each_counts = pd.concat([data_set.S1 == i, data_set.S2 == i, data_set.S3 == i, data_set.S4 == i,data_set.S5 == i], axis=1)\n",
    "        suit_counts.append(np.sum(each_counts, axis=1))\n",
    "    suit_counts = np.vstack(suit_counts)\n",
    "    suit_counts_df = pd.DataFrame(suit_counts.transpose(), columns=['S{}_Count'.format(i) for i in range(1,5)])\n",
    "    return pd.concat([suit_counts_df, data_set], axis=1)\n",
    "\n",
    "x_train=concat_suit_count(x_train)\n",
    "x_test=concat_suit_count(x_test)\n",
    "\n",
    "def concat_suit_value_count(data_set):\n",
    "    suit_counts = []\n",
    "    for i in range(0, 6):\n",
    "        each_counts = pd.concat([data_set.S1_Count == i, data_set.S2_Count == i, data_set.S3_Count == i, data_set.S4_Count == i], axis=1)\n",
    "        suit_counts.append(np.sum(each_counts, axis=1))\n",
    "    suit_counts = np.vstack(suit_counts)\n",
    "    suit_counts_df = pd.DataFrame(suit_counts.transpose(), columns=['Suit_Value_Count_{}'.format(i) for i in range(0,6)])\n",
    "    return pd.concat([suit_counts_df, data_set], axis=1)\n",
    "\n",
    "x_train=concat_suit_value_count(x_train)\n",
    "x_test=concat_suit_value_count(x_test)\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=20)\n",
    "clf=clf.fit(x_train,y_train)\n",
    "print(classification_report(y_test,clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score for type 5 is perfect now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the important feature for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tiger/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:5: FutureWarning: sort is deprecated, use sort_values(inplace=True) for INPLACE sorting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature C7_Count (0.074869)\n",
      "2. feature C6_Count (0.069245)\n",
      "3. feature C4_Count (0.068463)\n",
      "4. feature C5_Count (0.067630)\n",
      "5. feature C3_Count (0.066806)\n",
      "6. feature C2_Count (0.065912)\n",
      "7. feature C11_Count (0.065912)\n",
      "8. feature C8_Count (0.065256)\n",
      "9. feature C1_Count (0.063808)\n",
      "10. feature C13_Count (0.063756)\n",
      "11. feature C9_Count (0.062801)\n",
      "12. feature C12_Count (0.062085)\n",
      "13. feature C10_Count (0.060787)\n",
      "14. feature Card_std (0.057229)\n",
      "15. feature C3 (0.009607)\n",
      "16. feature C1 (0.009509)\n",
      "17. feature C4 (0.009483)\n",
      "18. feature C5 (0.009445)\n",
      "19. feature C2 (0.009404)\n",
      "20. feature S4_Count (0.005268)\n",
      "21. feature S2_Count (0.004849)\n",
      "22. feature S3_Count (0.004784)\n",
      "23. feature S1_Count (0.004161)\n",
      "24. feature S5 (0.003934)\n",
      "25. feature S1 (0.003855)\n",
      "26. feature S4 (0.003831)\n",
      "27. feature S2 (0.003664)\n",
      "28. feature S3 (0.003645)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAD8CAYAAACsAHnpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10de9e358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "def feature_importance(forest):\n",
    "    feature_importance = pd.Series(forest.feature_importances_, index=x_train.columns)\n",
    "    feature_importance.sort(inplace=True,ascending=False)\n",
    "    print(\"Feature ranking:\")\n",
    "    for f in range(x_train.shape[1]):\n",
    "        print(\"%d. feature %s (%f)\" % (f+1,feature_importance.index[f], feature_importance[f]))\n",
    "    feature_importance.plot(kind=\"barh\")\n",
    "feature_importance(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to remove raw features\n",
    "* Too many features will cause overfitting\n",
    "* Raw features contains same information as extracted features\n",
    "* if remove raw features will harm a lot of performance, that means we haven't extracted all information from raw features yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    501209\n",
      "          1       1.00      1.00      1.00    422498\n",
      "          2       0.98      0.98      0.98     47622\n",
      "          3       0.98      0.97      0.98     21121\n",
      "          4       1.00      1.00      1.00      3885\n",
      "          5       1.00      0.99      0.99      1996\n",
      "          6       0.91      0.07      0.13      1424\n",
      "          7       1.00      0.04      0.08       230\n",
      "          8       1.00      0.50      0.67        12\n",
      "          9       0.75      1.00      0.86         3\n",
      "\n",
      "avg / total       1.00      1.00      1.00   1000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train=train[['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5']] \n",
    "y_train=train['Type']\n",
    "x_test=test[['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5']]\n",
    "y_test=test['Type']\n",
    "\n",
    "def concat_card_count(data_set):\n",
    "    suit_counts = []\n",
    "    for i in range(1, 14):\n",
    "        each_counts = pd.concat([data_set.C1 == i, data_set.C2 == i, data_set.C3 == i, data_set.C4 == i,data_set.C5 == i], axis=1)\n",
    "        suit_counts.append(np.sum(each_counts, axis=1))\n",
    "    suit_counts = np.vstack(suit_counts)\n",
    "    suit_counts_df = pd.DataFrame(suit_counts.transpose(), columns=['C{}_Count'.format(i) for i in range(1,14)])\n",
    "    return pd.concat([suit_counts_df, data_set], axis=1)\n",
    "\n",
    "x_train = concat_card_count(x_train)\n",
    "x_test = concat_card_count(x_test)\n",
    "\n",
    "def concat_card_std(data_set):\n",
    "    hands=data_set[['C1','C2','C3','C4','C5']].as_matrix()\n",
    "    std=np.std(hands,axis=1)\n",
    "    hands[hands==1] =14\n",
    "    new_std = np.std(hands, axis=1)\n",
    "    std[new_std<std] = new_std[new_std < std]\n",
    "    std_df=pd.DataFrame(std,columns=['Card_std'])\n",
    "    return pd.concat([std_df,data_set],axis=1)\n",
    "x_train=concat_card_std(x_train)\n",
    "x_test=concat_card_std(x_test)\n",
    "\n",
    "def concat_suit_count(data_set):\n",
    "    suit_counts = []\n",
    "    for i in range(1, 5):\n",
    "        each_counts = pd.concat([data_set.S1 == i, data_set.S2 == i, data_set.S3 == i, data_set.S4 == i,data_set.S5 == i], axis=1)\n",
    "        suit_counts.append(np.sum(each_counts, axis=1))\n",
    "    suit_counts = np.vstack(suit_counts)\n",
    "    suit_counts_df = pd.DataFrame(suit_counts.transpose(), columns=['S{}_Count'.format(i) for i in range(1,5)])\n",
    "    return pd.concat([suit_counts_df, data_set], axis=1)\n",
    "\n",
    "x_train=concat_suit_count(x_train)\n",
    "x_test=concat_suit_count(x_test)\n",
    "\n",
    "def concat_suit_value_count(data_set):\n",
    "    suit_counts = []\n",
    "    for i in range(0, 6):\n",
    "        each_counts = pd.concat([data_set.S1_Count == i, data_set.S2_Count == i, data_set.S3_Count == i, data_set.S4_Count == i], axis=1)\n",
    "        suit_counts.append(np.sum(each_counts, axis=1))\n",
    "    suit_counts = np.vstack(suit_counts)\n",
    "    suit_counts_df = pd.DataFrame(suit_counts.transpose(), columns=['Suit_Value_Count_{}'.format(i) for i in range(0,6)])\n",
    "    return pd.concat([suit_counts_df, data_set], axis=1)\n",
    "\n",
    "x_train=concat_suit_value_count(x_train)\n",
    "x_test=concat_suit_value_count(x_test)\n",
    "\n",
    "x_train = x_train.drop(['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5'], axis=1)\n",
    "x_test = x_test.drop(['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5'], axis=1)\n",
    "\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=20)\n",
    "clf=clf.fit(x_train,y_train)\n",
    "print(classification_report(y_test,clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The performance does not drop a lot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add hand value count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    501209\n",
      "          1       1.00      1.00      1.00    422498\n",
      "          2       1.00      1.00      1.00     47622\n",
      "          3       1.00      1.00      1.00     21121\n",
      "          4       1.00      1.00      1.00      3885\n",
      "          5       1.00      1.00      1.00      1996\n",
      "          6       1.00      1.00      1.00      1424\n",
      "          7       1.00      1.00      1.00       230\n",
      "          8       1.00      0.75      0.86        12\n",
      "          9       0.75      1.00      0.86         3\n",
      "\n",
      "avg / total       1.00      1.00      1.00   1000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train=train[['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5']] \n",
    "y_train=train['Type']\n",
    "x_test=test[['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5']]\n",
    "y_test=test['Type']\n",
    "\n",
    "def concat_card_count(data_set):\n",
    "    suit_counts = []\n",
    "    for i in range(1, 14):\n",
    "        each_counts = pd.concat([data_set.C1 == i,\n",
    "                                 data_set.C2 == i, \n",
    "                                 data_set.C3 == i, \n",
    "                                 data_set.C4 == i,\n",
    "                                 data_set.C5 == i], axis=1)\n",
    "        suit_counts.append(np.sum(each_counts, axis=1))\n",
    "    suit_counts = np.vstack(suit_counts)\n",
    "    suit_counts_df = pd.DataFrame(suit_counts.transpose(), columns=['C{}_Count'.format(i) for i in range(1,14)])\n",
    "    return pd.concat([suit_counts_df, data_set], axis=1)\n",
    "\n",
    "x_train = concat_card_count(x_train)\n",
    "x_test = concat_card_count(x_test)\n",
    "\n",
    "def concat_card_std(data_set):\n",
    "    hands=data_set[['C1','C2','C3','C4','C5']].as_matrix()\n",
    "    std=np.std(hands,axis=1)\n",
    "    hands[hands==1] =14\n",
    "    new_std = np.std(hands, axis=1)\n",
    "    std[new_std<std] = new_std[new_std < std]\n",
    "    std_df=pd.DataFrame(std,columns=['Card_std'])\n",
    "    return pd.concat([std_df,data_set],axis=1)\n",
    "x_train=concat_card_std(x_train)\n",
    "x_test=concat_card_std(x_test)\n",
    "\n",
    "def concat_suit_count(data_set):\n",
    "    suit_counts = []\n",
    "    for i in range(1, 5):\n",
    "        each_counts = pd.concat([data_set.S1 == i,\n",
    "                                 data_set.S2 == i,\n",
    "                                 data_set.S3 == i,\n",
    "                                 data_set.S4 == i,\n",
    "                                 data_set.S5 == i], axis=1)\n",
    "        suit_counts.append(np.sum(each_counts, axis=1))\n",
    "    suit_counts = np.vstack(suit_counts)\n",
    "    suit_counts_df = pd.DataFrame(suit_counts.transpose(), columns=['S{}_Count'.format(i) for i in range(1,5)])\n",
    "    return pd.concat([suit_counts_df, data_set], axis=1)\n",
    "\n",
    "x_train=concat_suit_count(x_train)\n",
    "x_test=concat_suit_count(x_test)\n",
    "\n",
    "def concat_suit_value_count(data_set):\n",
    "    suit_counts = []\n",
    "    for i in range(0, 6):\n",
    "        each_counts = pd.concat([data_set.S1_Count == i,\n",
    "                                 data_set.S2_Count == i, \n",
    "                                 data_set.S3_Count == i, \n",
    "                                 data_set.S4_Count == i], \n",
    "                                axis=1)\n",
    "        suit_counts.append(np.sum(each_counts, axis=1))\n",
    "    suit_counts = np.vstack(suit_counts)\n",
    "    suit_counts_df = pd.DataFrame(suit_counts.transpose(), columns=['Suit_Value_Count_{}'.format(i) for i in range(0,6)])\n",
    "    return pd.concat([suit_counts_df, data_set], axis=1)\n",
    "\n",
    "x_train=concat_suit_value_count(x_train)\n",
    "x_test=concat_suit_value_count(x_test)\n",
    "\n",
    "x_train = x_train.drop(['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5'], axis=1)\n",
    "x_test = x_test.drop(['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5'], axis=1)\n",
    "\n",
    "def concat_hand_value_count(data_set):\n",
    "    suit_counts = []\n",
    "    for i in range(0, 6):\n",
    "        each_counts = pd.concat([data_set.C1_Count == i,\n",
    "                                 data_set.C2_Count == i, \n",
    "                                 data_set.C3_Count == i, \n",
    "                                 data_set.C4_Count == i,\n",
    "                                 data_set.C5_Count == i,\n",
    "                                 data_set.C6_Count == i, \n",
    "                                 data_set.C7_Count == i, \n",
    "                                 data_set.C8_Count == i,\n",
    "                                 data_set.C9_Count == i,\n",
    "                                 data_set.C10_Count == i, \n",
    "                                 data_set.C11_Count == i, \n",
    "                                 data_set.C12_Count == i,\n",
    "                                 data_set.C13_Count == i,\n",
    "                                ], axis=1)\n",
    "        suit_counts.append(np.sum(each_counts, axis=1))\n",
    "    suit_counts = np.vstack(suit_counts)\n",
    "    suit_counts_df = pd.DataFrame(suit_counts.transpose(),\n",
    "                                  columns=['Card_Value_Count_{}'.format(i) for i in range(0,6)])\n",
    "    return pd.concat([suit_counts_df, data_set], axis=1)\n",
    "\n",
    "x_train=concat_hand_value_count(x_train)\n",
    "x_test=concat_hand_value_count(x_test)\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=20)\n",
    "clf=clf.fit(x_train,y_train)\n",
    "print(classification_report(y_test,clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This feature helps improve type 6 result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add flag for the Ace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    501209\n",
      "          1       1.00      1.00      1.00    422498\n",
      "          2       1.00      1.00      1.00     47622\n",
      "          3       1.00      1.00      1.00     21121\n",
      "          4       1.00      1.00      1.00      3885\n",
      "          5       1.00      1.00      1.00      1996\n",
      "          6       1.00      1.00      1.00      1424\n",
      "          7       1.00      1.00      1.00       230\n",
      "          8       1.00      0.83      0.91        12\n",
      "          9       1.00      1.00      1.00         3\n",
      "\n",
      "avg / total       1.00      1.00      1.00   1000000\n",
      "\n",
      "0.999998\n"
     ]
    }
   ],
   "source": [
    "x_train=train[['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5']] \n",
    "y_train=train['Type']\n",
    "x_test=test[['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5']]\n",
    "y_test=test['Type']\n",
    "\n",
    "def concat_card_count(data_set):\n",
    "    suit_counts = []\n",
    "    for i in range(1, 14):\n",
    "        each_counts = pd.concat([data_set.C1 == i,\n",
    "                                 data_set.C2 == i, \n",
    "                                 data_set.C3 == i, \n",
    "                                 data_set.C4 == i,\n",
    "                                 data_set.C5 == i], axis=1)\n",
    "        suit_counts.append(np.sum(each_counts, axis=1))\n",
    "    suit_counts = np.vstack(suit_counts)\n",
    "    suit_counts_df = pd.DataFrame(suit_counts.transpose(), columns=['C{}_Count'.format(i) for i in range(1,14)])\n",
    "    return pd.concat([suit_counts_df, data_set], axis=1)\n",
    "\n",
    "x_train = concat_card_count(x_train)\n",
    "x_test = concat_card_count(x_test)\n",
    "\n",
    "def concat_card_std(data_set):\n",
    "    hands=data_set[['C1','C2','C3','C4','C5']].as_matrix()\n",
    "    std=np.std(hands,axis=1)\n",
    "    hands[hands==1] =14\n",
    "    new_std = np.std(hands, axis=1)\n",
    "    std[new_std<std] = new_std[new_std < std]\n",
    "    std_df=pd.DataFrame(std,columns=['Card_std'])\n",
    "    return pd.concat([std_df,data_set],axis=1)\n",
    "x_train=concat_card_std(x_train)\n",
    "x_test=concat_card_std(x_test)\n",
    "\n",
    "def concat_suit_count(data_set):\n",
    "    suit_counts = []\n",
    "    for i in range(1, 5):\n",
    "        each_counts = pd.concat([data_set.S1 == i,\n",
    "                                 data_set.S2 == i,\n",
    "                                 data_set.S3 == i,\n",
    "                                 data_set.S4 == i,\n",
    "                                 data_set.S5 == i], axis=1)\n",
    "        suit_counts.append(np.sum(each_counts, axis=1))\n",
    "    suit_counts = np.vstack(suit_counts)\n",
    "    suit_counts_df = pd.DataFrame(suit_counts.transpose(), columns=['S{}_Count'.format(i) for i in range(1,5)])\n",
    "    return pd.concat([suit_counts_df, data_set], axis=1)\n",
    "\n",
    "x_train=concat_suit_count(x_train)\n",
    "x_test=concat_suit_count(x_test)\n",
    "\n",
    "def concat_suit_value_count(data_set):\n",
    "    suit_counts = []\n",
    "    for i in range(0, 6):\n",
    "        each_counts = pd.concat([data_set.S1_Count == i,\n",
    "                                 data_set.S2_Count == i, \n",
    "                                 data_set.S3_Count == i, \n",
    "                                 data_set.S4_Count == i], \n",
    "                                axis=1)\n",
    "        suit_counts.append(np.sum(each_counts, axis=1))\n",
    "    suit_counts = np.vstack(suit_counts)\n",
    "    suit_counts_df = pd.DataFrame(suit_counts.transpose(), columns=['Suit_Value_Count_{}'.format(i) for i in range(0,6)])\n",
    "    return pd.concat([suit_counts_df, data_set], axis=1)\n",
    "\n",
    "x_train=concat_suit_value_count(x_train)\n",
    "x_test=concat_suit_value_count(x_test)\n",
    "\n",
    "x_train = x_train.drop(['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5'], axis=1)\n",
    "x_test = x_test.drop(['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5'], axis=1)\n",
    "\n",
    "def concat_hand_value_count(data_set):\n",
    "    suit_counts = []\n",
    "    for i in range(0, 6):\n",
    "        each_counts = pd.concat([data_set.C1_Count == i,\n",
    "                                 data_set.C2_Count == i, \n",
    "                                 data_set.C3_Count == i, \n",
    "                                 data_set.C4_Count == i,\n",
    "                                 data_set.C5_Count == i,\n",
    "                                 data_set.C6_Count == i, \n",
    "                                 data_set.C7_Count == i, \n",
    "                                 data_set.C8_Count == i,\n",
    "                                 data_set.C9_Count == i,\n",
    "                                 data_set.C10_Count == i, \n",
    "                                 data_set.C11_Count == i, \n",
    "                                 data_set.C12_Count == i,\n",
    "                                 data_set.C13_Count == i,\n",
    "                                ], axis=1)\n",
    "        suit_counts.append(np.sum(each_counts, axis=1))\n",
    "    suit_counts = np.vstack(suit_counts)\n",
    "    suit_counts_df = pd.DataFrame(suit_counts.transpose(),\n",
    "                                  columns=['Card_Value_Count_{}'.format(i) for i in range(0,6)])\n",
    "    return pd.concat([suit_counts_df, data_set], axis=1)\n",
    "\n",
    "x_train=concat_hand_value_count(x_train)\n",
    "x_test=concat_hand_value_count(x_test)\n",
    "\n",
    "def concat_Ace_flag(data_set):\n",
    "    data_set['Ace_flag']=data_set['C1_Count']==1\n",
    "    return data_set\n",
    "    \n",
    "x_train=concat_Ace_flag(x_train)\n",
    "x_test=concat_Ace_flag(x_test)\n",
    "\n",
    "\n",
    "clf=RandomForestClassifier(n_estimators=20)\n",
    "clf=clf.fit(x_train,y_train)\n",
    "print(classification_report(y_test,clf.predict(x_test)))\n",
    "print(accuracy_score(y_test,clf.predict(x_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
